{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "410489fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb34880",
   "metadata": {},
   "source": [
    "##### Load Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eba0c8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 88)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Sample Dataset\n",
    "df = pd.read_csv('../data/processed/sample_dataset.csv')\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1676608d",
   "metadata": {},
   "source": [
    "#### Cleanup Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3fbfff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace infinity with np.nan\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "202f40e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(960, 88)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with any NaN values\n",
    "nan_count = df.isna().sum().sum()\n",
    "print(nan_count)\n",
    "\n",
    "# Drop rows with any NaN values\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b9af878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(960, 88)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicate rows\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(duplicate_count)\n",
    "\n",
    "# Drop duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d322c877",
   "metadata": {},
   "source": [
    "#### Column Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4614c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stripping whitespace from column names and lowercasing\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc3bdb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unnamed:_0', 'flow_id', 'source_ip', 'source_port', 'destination_ip',\n",
       "       'destination_port', 'protocol', 'timestamp', 'flow_duration',\n",
       "       'total_fwd_packets', 'total_backward_packets',\n",
       "       'total_length_of_fwd_packets', 'total_length_of_bwd_packets',\n",
       "       'fwd_packet_length_max', 'fwd_packet_length_min',\n",
       "       'fwd_packet_length_mean', 'fwd_packet_length_std',\n",
       "       'bwd_packet_length_max', 'bwd_packet_length_min',\n",
       "       'bwd_packet_length_mean', 'bwd_packet_length_std', 'flow_bytes/s',\n",
       "       'flow_packets/s', 'flow_iat_mean', 'flow_iat_std', 'flow_iat_max',\n",
       "       'flow_iat_min', 'fwd_iat_total', 'fwd_iat_mean', 'fwd_iat_std',\n",
       "       'fwd_iat_max', 'fwd_iat_min', 'bwd_iat_total', 'bwd_iat_mean',\n",
       "       'bwd_iat_std', 'bwd_iat_max', 'bwd_iat_min', 'fwd_psh_flags',\n",
       "       'bwd_psh_flags', 'fwd_urg_flags', 'bwd_urg_flags', 'fwd_header_length',\n",
       "       'bwd_header_length', 'fwd_packets/s', 'bwd_packets/s',\n",
       "       'min_packet_length', 'max_packet_length', 'packet_length_mean',\n",
       "       'packet_length_std', 'packet_length_variance', 'fin_flag_count',\n",
       "       'syn_flag_count', 'rst_flag_count', 'psh_flag_count', 'ack_flag_count',\n",
       "       'urg_flag_count', 'cwe_flag_count', 'ece_flag_count', 'down/up_ratio',\n",
       "       'average_packet_size', 'avg_fwd_segment_size', 'avg_bwd_segment_size',\n",
       "       'fwd_header_length.1', 'fwd_avg_bytes/bulk', 'fwd_avg_packets/bulk',\n",
       "       'fwd_avg_bulk_rate', 'bwd_avg_bytes/bulk', 'bwd_avg_packets/bulk',\n",
       "       'bwd_avg_bulk_rate', 'subflow_fwd_packets', 'subflow_fwd_bytes',\n",
       "       'subflow_bwd_packets', 'subflow_bwd_bytes', 'init_win_bytes_forward',\n",
       "       'init_win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n",
       "       'active_mean', 'active_std', 'active_max', 'active_min', 'idle_mean',\n",
       "       'idle_std', 'idle_max', 'idle_min', 'simillarhttp', 'inbound', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e19b69",
   "metadata": {},
   "source": [
    "#### Feature Seperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88bdd0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((960, 87), (960,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperating X (Input) & Y (Output)\n",
    "y = df['label']\n",
    "X = df.drop(columns=['label'])\n",
    "\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff27b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['flow_id', 'source_ip', 'destination_ip', 'timestamp'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(960, 83)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing non-numeric features\n",
    "non_numeric_columns = X.select_dtypes(exclude=['number']).columns\n",
    "print(non_numeric_columns)\n",
    "\n",
    "if len(non_numeric_columns) > 0:\n",
    "  X = X.drop(columns=non_numeric_columns)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a2fd26",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a6f04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Standard Scaler is a normalization technique in machine learning that transforms numerical features so each of them has a mean of 0 and a standard deviation of 1. This process is known as standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db7c5e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 24)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead of using all 70+ of your scaled numeric features, PCA combines them into a smaller set of new, super-features called \"Principal Components.\" These new features are abstract, but they are engineered to capture the most important information (the most variance) from the original data.\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=24)\n",
    "\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e69984c",
   "metadata": {},
   "source": [
    "#### Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d2b2dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 24)\n",
      "(384, 24)\n",
      "(576,)\n",
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_data = X_pca\n",
    "y_data = y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.4, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acad382",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c229859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Complete\n",
      "Successfully saved metrics to ../output/lr_metrics.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/lr_model.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "results_dir = '../output'\n",
    "models_dir = '../models'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Train model\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "start_time = time.time()\n",
    "lr_model.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time_lr = end_time - start_time\n",
    "\n",
    "print(\"Training Complete\")\n",
    "\n",
    "\n",
    "# Predict the model\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_proba_lr = lr_model.predict_proba(X_test)\n",
    "\n",
    "# Get all metrics\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "# We add 'labels=lr_model.classes_' to tell the scorer about ALL possible classes\n",
    "auc_lr = roc_auc_score(y_test, y_proba_lr, multi_class='ovr', labels=lr_model.classes_)\n",
    "report_lr = classification_report(y_test, y_pred_lr)\n",
    "\n",
    "# Saving the metrics\n",
    "# --- 6. Save Metrics to a File ---\n",
    "file_path = os.path.join(results_dir, 'lr_metrics.txt')\n",
    "with open(file_path, 'w') as f:\n",
    "    f.write(\"--- METRICS FOR LOGISTIC REGRESSION ---\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy_lr * 100:.2f}%\\n\")\n",
    "    # ... (rest of the metrics writing) ...\n",
    "    f.write(report_lr)\n",
    "\n",
    "print(f\"Successfully saved metrics to {file_path}\")\n",
    "\n",
    "# Save the Trained Model\n",
    "model_path = os.path.join(models_dir, 'lr_model.joblib')\n",
    "joblib.dump(lr_model, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b1b564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "410489fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb34880",
   "metadata": {},
   "source": [
    "##### Load Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eba0c8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 88)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Sample Dataset\n",
    "df = pd.read_csv('../data/processed/sample_dataset.csv')\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1676608d",
   "metadata": {},
   "source": [
    "#### Cleanup Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3fbfff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace infinity with np.nan\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "202f40e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(960, 88)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with any NaN values\n",
    "nan_count = df.isna().sum().sum()\n",
    "print(nan_count)\n",
    "\n",
    "# Drop rows with any NaN values\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b9af878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(960, 88)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicate rows\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(duplicate_count)\n",
    "\n",
    "# Drop duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d322c877",
   "metadata": {},
   "source": [
    "#### Column Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4614c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stripping whitespace from column names and lowercasing\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc3bdb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unnamed:_0', 'flow_id', 'source_ip', 'source_port', 'destination_ip',\n",
       "       'destination_port', 'protocol', 'timestamp', 'flow_duration',\n",
       "       'total_fwd_packets', 'total_backward_packets',\n",
       "       'total_length_of_fwd_packets', 'total_length_of_bwd_packets',\n",
       "       'fwd_packet_length_max', 'fwd_packet_length_min',\n",
       "       'fwd_packet_length_mean', 'fwd_packet_length_std',\n",
       "       'bwd_packet_length_max', 'bwd_packet_length_min',\n",
       "       'bwd_packet_length_mean', 'bwd_packet_length_std', 'flow_bytes/s',\n",
       "       'flow_packets/s', 'flow_iat_mean', 'flow_iat_std', 'flow_iat_max',\n",
       "       'flow_iat_min', 'fwd_iat_total', 'fwd_iat_mean', 'fwd_iat_std',\n",
       "       'fwd_iat_max', 'fwd_iat_min', 'bwd_iat_total', 'bwd_iat_mean',\n",
       "       'bwd_iat_std', 'bwd_iat_max', 'bwd_iat_min', 'fwd_psh_flags',\n",
       "       'bwd_psh_flags', 'fwd_urg_flags', 'bwd_urg_flags', 'fwd_header_length',\n",
       "       'bwd_header_length', 'fwd_packets/s', 'bwd_packets/s',\n",
       "       'min_packet_length', 'max_packet_length', 'packet_length_mean',\n",
       "       'packet_length_std', 'packet_length_variance', 'fin_flag_count',\n",
       "       'syn_flag_count', 'rst_flag_count', 'psh_flag_count', 'ack_flag_count',\n",
       "       'urg_flag_count', 'cwe_flag_count', 'ece_flag_count', 'down/up_ratio',\n",
       "       'average_packet_size', 'avg_fwd_segment_size', 'avg_bwd_segment_size',\n",
       "       'fwd_header_length.1', 'fwd_avg_bytes/bulk', 'fwd_avg_packets/bulk',\n",
       "       'fwd_avg_bulk_rate', 'bwd_avg_bytes/bulk', 'bwd_avg_packets/bulk',\n",
       "       'bwd_avg_bulk_rate', 'subflow_fwd_packets', 'subflow_fwd_bytes',\n",
       "       'subflow_bwd_packets', 'subflow_bwd_bytes', 'init_win_bytes_forward',\n",
       "       'init_win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward',\n",
       "       'active_mean', 'active_std', 'active_max', 'active_min', 'idle_mean',\n",
       "       'idle_std', 'idle_max', 'idle_min', 'simillarhttp', 'inbound', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e19b69",
   "metadata": {},
   "source": [
    "#### Feature Seperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88bdd0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((960, 87), (960,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperating X (Input) & Y (Output)\n",
    "y = df['label']\n",
    "X = df.drop(columns=['label'])\n",
    "\n",
    "X.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dff27b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['flow_id', 'source_ip', 'destination_ip', 'timestamp'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(960, 83)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing non-numeric features\n",
    "non_numeric_columns = X.select_dtypes(exclude=['number']).columns\n",
    "print(non_numeric_columns)\n",
    "\n",
    "if len(non_numeric_columns) > 0:\n",
    "  X = X.drop(columns=non_numeric_columns)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a2fd26",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a6f04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Standard Scaler is a normalization technique in machine learning that transforms numerical features so each of them has a mean of 0 and a standard deviation of 1. This process is known as standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db7c5e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 24)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead of using all 70+ of your scaled numeric features, PCA combines them into a smaller set of new, super-features called \"Principal Components.\" These new features are abstract, but they are engineered to capture the most important information (the most variance) from the original data.\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=24)\n",
    "\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e69984c",
   "metadata": {},
   "source": [
    "#### Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d2b2dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 24)\n",
      "(384, 24)\n",
      "(576,)\n",
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_data = X_pca\n",
    "y_data = y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.4, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acad382",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c229859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Complete: Logistic_Regression\n",
      "Successfully saved metrics to ../output/Logistic_Regression.txt\n",
      "Training Complete: KNN\n",
      "Successfully saved metrics to ../output/KNN.txt\n",
      "Training Complete: Random_Forest\n",
      "Successfully saved metrics to ../output/Random_Forest.txt\n",
      "Training Complete: SVM\n",
      "Successfully saved metrics to ../output/SVM.txt\n",
      "Training Complete: Naive_Bayes\n",
      "Successfully saved metrics to ../output/Naive_Bayes.txt\n",
      "Training Complete: Decision_Tree\n",
      "Successfully saved metrics to ../output/Decision_Tree.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Complete: AdaBoost\n",
      "Successfully saved metrics to ../output/AdaBoost.txt\n",
      "  -> ERROR training XGBoost: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5 6], got ['BENIGN' 'LDAP' 'MSSQL' 'NetBIOS' 'Portmap' 'Syn' 'UDP']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/mohaiminulhoque/Developer/Research/ddos-detection/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "# Folder Setup\n",
    "results_dir = '../output'\n",
    "models_dir = '../models'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# Train model\n",
    "models = {\n",
    "    \"Logistic_Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Random_Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"SVM\": SVC(probability=True),  # probability=True is needed for AUC\n",
    "    \"Naive_Bayes\": GaussianNB(),\n",
    "    \"Decision_Tree\": DecisionTreeClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        end_time = time.time()\n",
    "\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        print(f\"Training Complete: {name}\")\n",
    "\n",
    "        # Predict the model\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "\n",
    "        # Get all metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_proba, multi_class='ovr', labels=model.classes_)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "\n",
    "        # Saving the metrics\n",
    "        file_path = os.path.join(results_dir, f'{name}.txt')\n",
    "        with open(file_path, 'w') as f:\n",
    "            f.write(f\"--- METRICS FOR {name.upper} ---\\n\")\n",
    "            f.write(f\"Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "            # ... (rest of the metrics writing) ...\n",
    "            f.write(report)\n",
    "\n",
    "        print(f\"Successfully saved metrics to {file_path}\")\n",
    "\n",
    "        # Save the Trained Model\n",
    "        model_path = os.path.join(models_dir, f'{name}.joblib')\n",
    "        joblib.dump(model, model_path)\n",
    "    except Exception as e:\n",
    "        print(f\"  -> ERROR training {name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b1b564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
